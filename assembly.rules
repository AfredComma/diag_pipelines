import re
import csv

configfile: "config.yml"


rule trimmomatic:
    input:
        "reads/raw/{sample}_R1_001.fastq",
        "reads/raw/{sample}_R2_001.fastq"
    output:
        "reads/trimmed/{sample}_R1_paired.fastq",
        "reads/trimmed/{sample}_R1_unpaired.fastq",
        "reads/trimmed/{sample}_R2_paired.fastq",
        "reads/trimmed/{sample}_R2_unpaired.fastq",
        "logs/{sample}_trimmomatic.log"
    shell:
        "trimmomatic PE {input} {output[0]} {output[1]} {output[2]} {output[3]}  ILLUMINACLIP:/home/sacha/Téléchargements/Genomic_tools/Trimmomatic/adapters/TruSeq3-PE.fa:3:25:6 LEADING:35 TRAILING:35 SLIDINGWINDOW:4:15 MINLEN:60 &> {output[4]}"


rule fastqc:
    input:
        "reads/trimmed/{sample}_R1_paired.fastq",
        "reads/trimmed/{sample}_R2_paired.fastq"
    output:
        "reads/trimmed/fastqc/{sample}_R1_paired_fastqc.zip",
        "reads/trimmed/fastqc/{sample}_R2_paired_fastqc.zip",
        "reads/trimmed/fastqc/{sample}_R1_paired_fastqc.html",
        "reads/trimmed/fastqc/{sample}_R2_paired_fastqc.html"
    shell:
        "fastqc {input} -o reads/trimmed/fastqc/"
    
rule unzip_fastqc:
    input:
        "reads/trimmed/fastqc/{sample}_R1_paired_fastqc.zip",
        "reads/trimmed/fastqc/{sample}_R2_paired_fastqc.zip"
    output:
        "reads/trimmed/fastqc/{sample}_R1_paired_fastqc/summary.txt",
        "reads/trimmed/fastqc/{sample}_R2_paired_fastqc/summary.txt"
    shell:
        "unzip -D -u {input[0]} -d reads/trimmed/fastqc/ && unzip -D -u {input[1]} -d reads/trimmed/fastqc/ && touch {output[0]} &&  touch {output[1]}"

        
rule error_correction_spades:
    input:
        "reads/trimmed/{sample}_R1_paired.fastq",
        "reads/trimmed/{sample}_R2_paired.fastq"
    output:
        "reads/corrected/{sample}_R1_paired.00.0_0.cor.fastq.gz",
        "reads/corrected/{sample}_R2_paired.00.0_0.cor.fastq.gz"
    shell:
         "spades.py -1 {input[0]} -2 {input[1]} --only-error-correction -o $( dirname $(dirname {output[0]}))"
        
rule check_low_coverage_contigs:
    input:
        "assembly/spades/{sample}/contigs_500bp_low_kmer_coverage.fasta"
    output:
        "blast_check/{sample}/contig_low_kmer_coverage.txt"
    shell:
        "blastn -query {input[0]} -db dub -remote"
        
rule spades:
    input:
        "reads/corrected/{sample}_R1_paired.00.0_0.cor.fastq.gz",
        "reads/corrected/{sample}_R2_paired.00.0_0.cor.fastq.gz"
    output:
        "assembly/spades/{sample}/spades.log",
        "assembly/spades/{sample}/contigs.fasta"
    shell:
        "spades.py -1 {input[0]} -2 {input[1]} -o $( dirname {output[0]})"

rule quast:
    input:
        "assembly/spades/{sample}/contigs_500bp_high_kmer_coverage.fasta"
    output:
        "assembly/spades/{sample}/quast/report.txt"
    shell:
        "quast.py {input} -o $( dirname {output})"

rule extract_contigs_500bp:
    input:
        "assembly/spades/{sample}/contigs.fasta"
    output:
        "assembly/spades/{sample}/contigs_500bp.fasta"
    shell:
        "awk '/^>/{{print (NR==1)?$0: \"\\n\" $0;next}} {{printf \"%s\", $0}}END{{print \"\"}}' {input} |  awk \'!/^>/ {{ next }} {{ getline seq }} length(seq) >= 500 {{ print $0 \"\\n\" seq }}\'  > {output}"  


rule rename_contigs:
    input:
        "assembly/spades/{sample}/contigs_500bp_high_kmer_coverage.fasta"
    output:
        "assembly/spades/{sample}/contigs_500bp_high_kmer_coverage_renamed.fasta"
    shell:
        "sed \"s/NODE_\\([0-9]\\+\\)_.*/contig00\\1/\" {input} > {output}"
        
rule prokka:
    input:
        "assembly/spades/{sample}/contigs_500bp_high_kmer_coverage_renamed.fasta"
    output:
        "annotation/{sample}/genes.log",
        "annotation/{sample}/genes.gff",
        "annotation/{sample}/genes.txt"
    shell:
        "prokka --outdir $( dirname {output[0]}) --force {input} --prefix genes"


rule check_coverage_assembly:
    input:
        "assembly/spades/{sample}/contigs_500bp.fasta"
    output:
        "assembly/spades/{sample}/contigs_500bp_low_kmer_coverage.txt",
        "assembly/spades/{sample}/contigs_500bp_high_kmer_coverage.txt"
    shell:
        "grep \">\" {input} | sed \"s/.*cov_//\" | awk '$1 < 5 {{print NR}}' | sed \"s/^/NODE_/\" | sed \"s/$/_/\" | sed \"s/^>//\" > {output[0]} && grep \">\" {input} | sed \"s/.*cov_//\" | awk '$1 > 5 {{print NR}}' | sed \"s/^/NODE_/\" | sed \"s/$/_/\" | sed \"s/^>//\"  > {output[1]} "


rule filter_contigs_on_coverage:
    input:
        "assembly/spades/{sample}/contigs_500bp.fasta",
        "assembly/spades/{sample}/contigs_500bp_high_kmer_coverage.txt",
        "assembly/spades/{sample}/contigs_500bp_low_kmer_coverage.txt"
    output:
        "assembly/spades/{sample}/contigs_500bp_high_kmer_coverage.fasta",
        "assembly/spades/{sample}/contigs_500bp_low_kmer_coverage.fasta"
    shell:
        "grep -A 1 -f {input[1]} {input[0]} | sed '/^--$/d' > {output[0]} && grep -A 1 -f {input[2]} {input[0]} | sed '/^--$/d' > {output[1]}"              

    
rule gff_to_embl:
    input:
        "annotation/{sample}/genes.gff"
    output:
        "{sample}/ena_submission/flatfile.embl"
    params:
        publ=config["publication"],
        id=config["taxon_id_number"],
        name=config["taxon_name"],
        PRJ=config["EBI_project_number"],
        desc=config["description_of_the_genome_sequence"],
        aut="'"+" ".join(config["authors"])+"'",
        tt=config["translation_table"],
        pre=config["prefix_locus_tag"]
    shell:
        "gff3_to_embl --translation_table {params.tt} --locus_tag {params.pre} --authors {params.aut} --classification PROK --publication {params.publ} --output_filename {output} {params.name} {params.id} {params.PRJ} {params.desc} {input} "

rule validate_gff_for_ena_submission:
    input:
        "{sample}/ena_submission/flatfile.embl"
    output:
        "{sample}/ena_submission/VAL_REPORTS.txt"
    shell:
        "cd $( dirname {input}) && embl-api-validator $( basename {input}) "
        

def extract_report_fastqc(filename, pattern):
    s=''
    with open(filename) as text:
        for i, line in enumerate(text):
            if pattern.search(line) is not None:
                s=s+line+"\n"
    return s

def extract_report_quast(filename):
    with open(filename) as text:
        l = text.readlines()
        return "\n".join(l[-9:-1])

def extract_report_trimmomatic(filename):
    with open(filename) as f:
        lines = f.read().splitlines()
        return [int(s) for s in lines[-2].split() if s.isdigit()]

def format_table(string):
    s = "    "
    for i in string.split("\n"):
        if len(i):
            s = s + "\t".join(i.split("\t")[0:2]) + "\n    " 
    return(s)

def extract_info_quast(l, index):
    return [x for x in l[index].split(" ") if x is not ""][-1]

def extract_info_prokka(filename):
    with open(filename) as f:
        d = {}
        for row in csv.reader(f, delimiter=":"):
            d[row[0]] = row[1]
        return(d)
    

rule report:
    input:
        trim = "logs/{sample}_trimmomatic.log",
        fastqc1 = "reads/trimmed/fastqc/{sample}_R1_paired_fastqc/summary.txt",
        fastqc2 = "reads/trimmed/fastqc/{sample}_R2_paired_fastqc/summary.txt",
        fastqc1html = "reads/trimmed/fastqc/{sample}_R1_paired_fastqc.html",
        fastqc2html = "reads/trimmed/fastqc/{sample}_R2_paired_fastqc.html",
        spades = "assembly/spades/{sample}/spades.log",
        low_cov_names = "assembly/spades/{sample}/contigs_500bp_low_kmer_coverage.txt",
        low_cov = "assembly/spades/{sample}/contigs_500bp_low_kmer_coverage.fasta",        
        quast = "assembly/spades/{sample}/quast/report.txt",
        prokka = "annotation/{sample}/gene.txt"
        
    output:
        "{sample}_report.html"
    run:
        from snakemake.utils import report
        trim_result = extract_report_trimmomatic(input["trim"])
        trim_result_percent = [ x / float(trim_result[0]) for x in trim_result ]
        trim_result_percent_strings = [ "{:2.1f}".format(x*100) for x in trim_result_percent ]
        warn = re.compile(r"WARN")
        fail = re.compile(r"FAIL")
        test2 = extract_report_fastqc(input["fastqc2"], fail)
        assembly = extract_report_quast(input["quast"]).split("\n")
        ncontigs = extract_info_quast(assembly, 0)
        largest_contig = extract_info_quast(assembly, 2)
        total_length = extract_info_quast(assembly, 4)
        gc =extract_info_quast(assembly, 6) 
        n50 = extract_info_quast(assembly, 8)
        r1f = format_table(extract_report_fastqc(input["fastqc1"], fail))
        r1w = format_table(extract_report_fastqc(input["fastqc1"], warn))
        r2f = format_table(extract_report_fastqc(input["fastqc2"], fail))
        r2w = format_table(extract_report_fastqc(input["fastqc2"], warn))
        spw = extract_report_fastqc(input["spades"], warn)
        spw = "    " + "\n    ".join([ x for x in spw.split("\n") if "*" in x ])
        if spw.isspace():
            spw = "    No warnings"
        contigs_excluded = "    "+"    ".join(open(input["low_cov_names"]).readlines()).replace("_", " ")
        prokka_annot = extract_info_prokka(input["prokka"])
        rRNA = prokka_annot["rRNA"]
        CDS = prokka_annot["CDS"]
        tRNA = prokka_annot["tRNA"]
        
        
        report("""
        Report of the assembly and annotation of the strain {wildcards.sample}
        ===========================================================================================
        Reads were trimmed using Trimmomatic.\n
        ====================================== =================================
        Total number of pairs                  {trim_result[0]}
        Total of pairs passing trimming        {trim_result[1]} ({trim_result_percent_strings[1]} %)
        Forward read only surviving            {trim_result[2]} ({trim_result_percent_strings[2]} %)
        Reverse read only surviving            {trim_result[3]} ({trim_result_percent_strings[3]} %)
        Both reads dropped                     {trim_result[4]} ({trim_result_percent_strings[4]} %)
        ====================================== =================================
        
        (File trim_)\n
        The quality check on the pairs with both reads passing trimming was performed using fastqc. Fastqc reported the following warnings and failures:\n
        For forward reads::        
            
        {r1w}
        {r1f}
        
        (File fastqc1html_) \n

        For reverse reads::

        {r2w}
        {r2f}
        
        (File fastqc2html_) \n
        Check the html fastqc files for the details of the quality checks.
        
        The genome was assembled using spades. Spades reported the following warnings::
        
        {spw}
        
        (File spades_) \n

        The contigs were filtered based on their kmer coverage and those that had too low coverage (less than 5) were excluded from the analysis. The excluded contigs were::
        
        {contigs_excluded}
        
        Try blasting their sequences (in file low_cov_) to check their origin.
        
        The statitics of the assembly, without the excluded contigs, were obtained with quast: 
        
        ================================= ==============================
        Number of contigs                 {ncontigs}
        Largest contig                    {largest_contig} bps
        Total length                      {total_length} bps
        GC content                        {gc} %
        N50                               {n50} bps
        ================================= ==============================
        
        Genes were annotated using prokka in local. 


        ================================= ==============================
        Number of CDS                     {CDS}
        Number of rRNA genes              {rRNA}
        Number of tRNA genes              {tRNA}
        ================================= ==============================
        """, output[0], **input)
