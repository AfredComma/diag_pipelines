import re
from snakemake.utils import report


configfile: "comparative_search.yml"

genus = config["search"]
genus_query = "|".join(genus)

shell.prefix("set -euo pipefail;") 

rule download_genomes_from_refseq:
    input:
        "refSeq/genome_addresses.txt"
    output:
        "refSeq/genomes/log_wget.txt"
    shell:
        "cut -f1,2,3,4 {input} | xargs -I{{}} sh -c \
        'str=$1; id=$(echo ${{str%%ftp:*}} | tr \" \" \"_\"); address=$(echo ftp:${{str##*ftp:}} | sed \"s/\(\/GCF_.*\)/\\1\\1_genomic.fna.gz/\"); echo ${{id}} ${{address}}; wget -O $(dirname {output})/${{id}}.fna.gz ${{address}}' -- {{}} > {output} "

rule download_proteomes_from_refseq:
    input:
        "refSeq/genome_addresses.txt"
    output:
        "refSeq/proteomes/log_wget.txt"
    shell:
        "cut -f1,2,4 {input} | xargs -I{{}} sh -c \
        'str=$1; id=$(echo ${{str%%ftp:*}} | tr \" \" \"_\"); address=$(echo ftp:${{str##*ftp:}} | sed \"s/\(\/GCF_.*\)/\\1\\1_protein.faa.gz/\"); echo ${{id}} ${{address}}; wget -O $(dirname {output})/${{id}}.faa.gz ${{address}}' -- {{}} > {output} "

        

rule extract_genome_refseq_info:
    input:
        "comparative_search.yml"
    output:
        "refSeq/nb_genomes_per_species.txt"
    shell:
        "esearch -db assembly -query \"{genus_query}\" | efetch -db assembly -format docsum | xtract.Linux -pattern DocumentSummary -if RefSeq -if Sub_value -element SpeciesName  | sort | uniq -c | sort -k 1 -n > {output}"


rule fetch_refSeq_id_and_filtering:
    input:
        "refSeq/nb_genomes_per_species.txt"
    output:
        "refSeq/genome_addresses.txt"
    shell:
        """
        if [ -f {output} ]
        then
            rm {output}
        fi
        awk '$1 > 5' {input} | awk '{{print $2, $3}}' | xargs -I{{}} sh -c 'esearch -db assembly -query \"$1\" | efetch -db assembly -format docsum | xtract.Linux -pattern DocumentSummary -unless RefSeq_category -equals \"na\" -if RefSeq -if Sub_value -element SpeciesName Sub_value RefSeq FtpPath_RefSeq >> {output}' -- {{}}
        awk '$1 < 5' {input} | awk '{{print $2, $3}}'|  xargs -I{{}} sh -c 'esearch -db assembly -query \"$1\" | efetch -db assembly -format docsum | xtract.Linux -pattern DocumentSummary -if RefSeq -if Sub_value -element SpeciesName Sub_value RefSeq FtpPath_RefSeq >> {output}' -- {{}}
        """
        
rule calculate_ani:
    input:
        "refSeq/genomes/log_unzip.txt",
        "local_genomes/id_local_genomes.txt"
    output:
        "ANI/log_pyani.txt"
    shell:
        """
        cp refSeq/genomes/*.fna $(dirname {output})
        cp local_genomes/*.fna $(dirname {output})
        average_nucleotide_identity.py -i $(dirname {output}) -o $( dirname {output})/results/ -l {output} -g --gformat eps,png -f
        """

        
rule unzip_proteomes:
    input:
        "refSeq/proteomes/log_wget.txt"
    output:
        "refSeq/proteomes/log_unzip.txt"
    shell:
        "for i in $( ls $( dirname {input})/*.gz);\
        do gzip -d -f $i;\
        done > {output}"


rule unzip_genomes:
    input:
        "refSeq/genomes/log_wget.txt"
    output:
        "refSeq/genomes/log_unzip.txt"
    shell:
        "for i in $( ls $( dirname {input})/*.gz);\
        do gzip -d -f $i;\
        done > {output}"   

        
rule orthofinder_downloaded_proteomes:
    input:
        "refSeq/proteomes/log_unzip.txt"
    output:
        "refSeq/orthologs/log_orthofinder.txt"
    shell:
        "orthofinder -f $( dirname {input}) -M msa > {output}"
    
rule adding_local_genomes_to_orthofinder_run:
    input:
        "refSeq/orthologs/log_orthofinder.txt",
        "local_genomes/id_local_genomes.txt"
    output:
        "orthologs/log_orthofinder.txt",
        "orthologs/SpeciesID.txt"
    shell:
        """
        last_remote_orthofinder_result=$( grep -A 1 -m 1 'Orthogroups have been written to tab-delimited files:' {input[0]} | tail -n 1 | sed 's/Orthogroups.csv/WorkingDirectory/' )
        orthofinder -b ${{last_remote_orthofinder_result}} -f $(dirname {input[1]}) -M msa > {output}
        sed "s/://" ${{last_remote_orthofinder_result}}/SpeciesID.txt | sed "s/\\.faa//" >  {output[1]}
        """

rule extracting_one_to_one_orthologs:
    input:
        "orthologs/log_orthofinder.txt",
        "refSeq/orthologs/log_orthofinder.txt"
    output:
        "orthologs/1to1groups/log.txt"
    shell:
        """
        out_folder=$(dirname {output})
        last_orthofinder_results=$(dirname $( grep -A 1 -m 1 'Orthogroups have been written to tab-delimited files:' {input[0]} | tail -n 1 ))
        echo ${{last_orthofinder_results}}
        last_single_copy_orthogroups=$( ls -Srt ${{last_orthofinder_results}}/SingleCopyOrthogroups_* | tail -n 1 | cut -f9 -d' ')
        echo ${{last_single_copy_orthogroups}}
        last_orthologues_folder=$( ls -Srtd ${{last_orthofinder_results}}/Orthologues_* | tail -n 1 | cut -f9 -d' ')
        echo ${{last_orthologues_folder}}
        alignmentsid_folder=${{last_orthologues_folder}}/WorkingDirectory/Alignments_ids/

        for og in $(cat ${{last_single_copy_orthogroups}})
        do
            awk '/^>/ {{printf("\\n%s\\n",$0);next; }} {{ printf("%s",$0);}}  END {{printf("\\n");}}' < ${{alignmentsid_folder}}/${{og}}.fa >  ${{out_folder}}/${{og}}_oneline.fa;
        done
        sed -i "s/>\([0-9]\+\)_.*/>\\1/" ${{out_folder}}/*_oneline.fa
        sed -i "/^\s*$/d" ${{out_folder}}/*_oneline.fa
        echo "Orthogroups extracted" >> {output}
        """

rule prepare_raxml_files:
    input:
        "orthologs/1to1groups/log.txt"
    output:
        "raxml/concatenated_orthogroups.fa",
        "raxml/partition_file.txt"
    shell:
        """
        target_folder=$(dirname {input})
        type=prot
        model=LG
        index=0
        start=1
        if [ -f {output[1]} ] 
        then
            rm {output[1]}
        fi
        for i in $(ls ${{target_folder}}/*_oneline.fa)
        do
            length=$(tail -n -1 ${{i}} | tr -d '\\n' | wc -m);
            echo "${{model}}, ${{type}}${{index}} = ${{start}}-$(( start + length - 1 ))" >> {output[1]}
            start=$(( start + length ));
            index=$(( index + 1 ));
        done
        paste -d'\\0' ${{target_folder}}/*_oneline.fa | sed "s/>\([0-9]\+\)>.*/>\\1/"  |  sed "/^\s*$/d" | sed "s/U/C/g" > {output[0]}
        """

        #sed "s/U/C/g" replaces Selenocysteine (U) which is not accepted by raxml by Cysteine (C) which is the closest AA possible

rule run_raxml_on_1to1groups:
    input:
        "raxml/concatenated_orthogroups.fa",
        "raxml/partition_file.txt"
    output:
        "raxml/RAxML_info.run",
        "raxml/RAxML_bestTree.run"
    shell:
        """
        if [ -f {output[0]} ]
        then
            rm {output[0]}
        fi
        raxmlHPC -m PROTGAMMALG -w $(dirname $(readlink -f {output[0]})) -n run -s {input[0]} -q {input[1]} -p 123 > $(dirname {output[0]})/logs.txt
        """

rule generate_tree_figure_from_raxml:
    input:
        "raxml/RAxML_bestTree.run",
        "orthologs/SpeciesIDs.txt"
    output:
        "raxml/tree.svg",
        "raxml/tree.png"
    shell:
        """
        nw_rename {input[0]} {input[1]} | nw_display -S -s -b 'opacity:0' -w 800 - > {output[0]}
        inkscape -z {output[0]} -e {output[1]}
        """
        
        
def extract_orthofinder_results(filename):
    s=""
    stats_file_pattern = re.compile(r"Statistics_Overall_\d+\.csv")
    folder_pattern = re.compile(r"existing analysis in /.*")
    stats_file = re.findall(stats_file_pattern, open(filename, "r").read())
    folder = re.findall(folder_pattern, open(filename, "r").read())
    return "\n    ".join(open(("/"+"/".join(folder[0].split("/")[1:])+stats_file[0]), "r").read().split("Date")[0].split("\n"))
        




rule report:
    input:
        species="refSeq/nb_genomes_per_species.txt",
        genomes="refSeq/genome_addresses.txt",
        local_genomes="local_genomes/id_local_genomes.txt",
        ortho="orthologs/log_orthofinder.txt",
        pyani="ANI/log_pyani.txt",
        tree="raxml/tree.png"
    output:
        "report.html"
    run:
        tree=input["tree"]
        queries="\n    ".join(genus)
        numbers=open(input["species"], "r").read()
        genomes="\n    ".join(open(input["genomes"], "r").read().split("\n"))
        idlocal="\n    ".join(open(input["local_genomes"], "r").read().split("\n"))
        report_ortho=extract_orthofinder_results(input["ortho"])
        report("""
        Report of the comparative genomics pipeline 
        ===========================================
        The RefSeq database was searched for the available genomes using the requested queries::
        
            {queries}

        The number of available genomes in RefSeq are, excluding the entries whos subspecies was not defined::
        
        {numbers}

        If species had more than 5 genomes available, only the reference and representative genomes were selected. Hence here are the genomes that were downloaded for this analysis::
            
            Species name\t Subspecies name\t RefSeqID \t FTP link
            {genomes}
        
        Additionnaly, here are the local genomes that were included in this analysis::
        
            {idlocal}

        Orthofinder was run on those genomes and the output statistics were::

            {report_ortho}
        
        A phylogeny was constructed using the single-copy orthogroups using RAxML:

        .. image:: {tree}

        The Average Nucleotide Identity (ANI) between all genomes was calculated using pyani. Here are the ANI values:

        .. image:: ANI/results/ANIm_percentage_identity.png
        
        And here is the percentage of the genome that was aligned:

        .. image:: ANI/results/ANIm_alignment_coverage.png
        """, output[0], **input)
        
