import pandas

pipeline_path = workflow.basedir + "/../../"

include:
    pipeline_path + "workflows/logging.rules"
    
enterobase = pandas.read_csv(pipeline_path+"/data/core_genome_dbs/enterobase_database.tsv", sep="\t", index_col=0)

rule all:
    input:
        "core_genomes/"+config["species"].replace(" ", "_")+"/enterobase/"+str(enterobase.loc[config["species"], "reference_genome"])+".bed"
        
include:
    pipeline_path + "downloading/fetch_single_reference.rules"

rule get_schema_from_enterobase:
    params:
        enterobase_scheme=enterobase.loc[config["species"], "scheme"],
        enterobase_species=enterobase.loc[config["species"], "species_id"],
    output:
        gene_list="core_genomes/{spec}/enterobase/genes.txt",
    shell:
        """
        wget -qO- http://enterobase.warwick.ac.uk/download_data?allele=profiles\&scheme={params.enterobase_scheme}\&species={params.enterobase_species} | gzip -d | head -n 1 | tr '[:space:]' '\\n' | tail -n +2 > {output[gene_list]} || :
        """

rule fetch_gene_entries_from_locus_tag:
    conda:
        "../../envs/biopython.yaml"
    input:
        gbk="references/{ref}/genome_gbwithparts.gbwithparts",
        locus_list="core_genomes/{spec}/enterobase/genes.txt",
    output:
        bed="core_genomes/{spec}/enterobase/{ref}.bed",
        problematic="core_genomes/{spec}/enterobase/{ref}_missing.txt",
    script:
        pipeline_path + "rules/core_genome/scripts/parse_gff_extract_locus_tags.py"
        


