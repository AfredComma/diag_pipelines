import pandas

pipeline_path = workflow.basedir + "/../../"

include:
    pipeline_path + "workflows/logging.rules"
    
include:
    pipeline_path + "rules/downloading/fetch_single_reference.rules"

species = config["species"].replace(" ", "_")
    
ridom = pandas.read_csv(pipeline_path + "data/core_genome_dbs/ridom_database.tsv", sep="\t", index_col=0)
 
rule get_scheme_from_ridom:
    params:
        id_ridom=str(ridom.loc[config["species"], "IdNumber"]),
    output:
        tsv="core_genomes/{spec}/ridom/schemas.tsv"
    shell:
        """
        wget -qO- http://www.cgmlst.org/ncs/schema/{params.id_ridom}/locus/?content-type=csv > {output[tsv]}
        """
    
rule create_bed_from_schema:
    input:
        schema = lambda wildcards: "core_genomes/{spec}/ridom/schemas.tsv",
        genome = lambda wildcards: "references/"+ str(ridom.loc[wildcards.spec, "ReferenceGenome"]) + "/genome_fasta.fasta",
    output:
        bed="core_genomes/{spec}/ridom.bed",
    shell:
        """    
        accession=$(head -n 1 {input[genome]} | cut -f1 -d ' ' | sed "s/>//") 
        tail -n +2 {input[schema]} | cut -f4,5 | awk -v acc="${{accession}}" '{{print acc "\011" ($1 - 1) "\011" ($1 -1 + $2)}}' > {output[bed]}
        """

rule all:
    input:
        "core_genomes/" + species + "/ridom.bed"
